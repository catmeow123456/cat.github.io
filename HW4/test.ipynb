{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  # 网页解析，获取数据\n",
    "import re  # 正则表达式，进行文字匹配`\n",
    "import urllib.request\n",
    "import urllib.error  # 制定URL，获取网页数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def askURL(url):\n",
    "    head = {  # 模拟浏览器头部信息，向豆瓣服务器发送消息\n",
    "        \"User-Agent\": \"Mozilla / 5.0(Windows NT 10.0; Win64; x64) AppleWebKit / 537.36(KHTML, like Gecko) Chrome / 80.0.3987.122  Safari / 537.36\"\n",
    "    }\n",
    "    # 用户代理，表示告诉豆瓣服务器，我们是什么类型的机器、浏览器（本质上是告诉浏览器，我们可以接收什么水平的文件内容）\n",
    "\n",
    "    request = urllib.request.Request(url, headers=head)\n",
    "    html = \"\"\n",
    "    try:\n",
    "        response = urllib.request.urlopen(request)\n",
    "        html = response.read().decode(\"utf-8\")\n",
    "    except urllib.error.URLError as e:\n",
    "        if hasattr(e, \"code\"):\n",
    "            print(e.code)\n",
    "        if hasattr(e, \"reason\"):\n",
    "            print(e.reason)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "findLink = re.compile(r'<a href=\"(.*?)\">')  # 创建正则表达式对象，标售规则   影片详情链接的规则\n",
    "findImgSrc = re.compile(r'<img.*src=\"(.*?)\"', re.S)\n",
    "findTitle = re.compile(r'<span class=\"title\">(.*)</span>')\n",
    "findRating = re.compile(r'<span class=\"rating_num\" property=\"v:average\">(.*)</span>')\n",
    "findJudge = re.compile(r'<span>(\\d*)人评价</span>')\n",
    "findInq = re.compile(r'<span class=\"inq\">(.*)</span>')\n",
    "findBd = re.compile(r'<p class=\"\">(.*?)</p>', re.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(baseurl):\n",
    "    datalist = []  # 用来存储爬取的网页信息\n",
    "    for i in range(0, 10):  # 调用获取页面信息的函数，10次\n",
    "        url = baseurl + str(i * 25)\n",
    "        html = askURL(url)  # 保存获取到的网页源码\n",
    "        # 2.逐一解析数据\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        for item in soup.find_all('div', class_=\"item\"):  # 查找符合要求的字符串\n",
    "            data = []  # 保存一部电影所有信息\n",
    "            item = str(item)\n",
    "            link = re.findall(findLink, item)[0]  # 通过正则表达式查找\n",
    "            data.append(link)\n",
    "            imgSrc = re.findall(findImgSrc, item)[0]\n",
    "            data.append(imgSrc)\n",
    "            titles = re.findall(findTitle, item)\n",
    "            if (len(titles) == 2):\n",
    "                ctitle = titles[0]\n",
    "                data.append(ctitle)\n",
    "                otitle = titles[1].replace(\"/\", \"\")  # 消除转义字符\n",
    "                data.append(otitle)\n",
    "            else:\n",
    "                data.append(titles[0])\n",
    "                data.append(' ')\n",
    "            rating = re.findall(findRating, item)[0]\n",
    "            data.append(rating)\n",
    "            judgeNum = re.findall(findJudge, item)[0]\n",
    "            data.append(judgeNum)\n",
    "            inq = re.findall(findInq, item)\n",
    "            if len(inq) != 0:\n",
    "                inq = inq[0].replace(\"。\", \"\")\n",
    "                data.append(inq)\n",
    "            else:\n",
    "                data.append(\" \")\n",
    "            bd = re.findall(findBd, item)[0]\n",
    "            bd = re.sub('<br(\\s+)?/>(\\s+)?', \"\", bd)\n",
    "            bd = re.sub('/', \"\", bd)\n",
    "            data.append(bd.strip())\n",
    "            datalist.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = \"https://movie.douban.com/top250?start=\"  # 要爬取的网页链接\n",
    "datalist = getData(baseurl)\n",
    "savepath = \"豆瓣电影Top250.xls\"    # 当前目录新建XLS，存储进去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
